#!/usr/bin/env python3
"""
‚ö° –ë–´–°–¢–†–´–ô –ü–ê–†–°–ï–† –í–ö–£–°–í–ò–õ–õ–ê –ü–û –ì–ï–û–õ–û–ö–ê–¶–ò–ò
–ë—ã—Å—Ç—Ä–æ —Å–æ–±–∏—Ä–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –∑–∞—Ö–æ–¥–∞ –≤ –∫–∞—Ä—Ç–æ—á–∫–∏.

–û–°–û–ë–ï–ù–ù–û–°–¢–ò:
- –ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–ª—å–∫–æ —Å –∫–∞—Ç–∞–ª–æ–∂–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–±–µ–∑ –∑–∞—Ö–æ–¥–∞ –≤ –∫–∞—Ä—Ç–æ—á–∫–∏)
- –°–±–æ—Ä —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: ID, –Ω–∞–∑–≤–∞–Ω–∏–µ, —Ü–µ–Ω–∞
- –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞ (—Å–µ–∫—É–Ω–¥—ã –≤–º–µ—Å—Ç–æ —á–∞—Å–æ–≤)
- –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –≥–µ–æ–ª–æ–∫–∞—Ü–∏–µ–π
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞–∑—É —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python3 address.py "–ê–¥—Ä–µ—Å" [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤]
python3 address.py  # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º

–ü–†–ò–ú–ï–†–´:
python3 address.py "–ú–æ—Å–∫–≤–∞, –ö—Ä–∞—Å–Ω–∞—è –ø–ª–æ—â–∞–¥—å, 1" 200
python3 address.py "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –ù–µ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç, 10" 300
python3 address.py "55.7558,37.6176" 100
python3 address.py  # –ó–∞–ø—É—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ
"""

import asyncio
import csv
import json
import logging
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urljoin, quote

try:
    from selectolax.parser import HTMLParser
except ImportError:
    HTMLParser = None

# –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã
import httpx
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError


class AntiBotClient:
    """–ü—Ä–æ—Å—Ç–æ–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã."""
    
    def __init__(self, concurrency: int = 10, timeout: int = 30):
        self.semaphore = asyncio.Semaphore(concurrency)
        self.timeout = timeout
        
    async def request(self, method: str, url: str, **kwargs):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å HTTP –∑–∞–ø—Ä–æ—Å."""
        async with self.semaphore:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            async with httpx.AsyncClient(timeout=self.timeout, headers=headers) as client:
                response = await client.request(method, url, **kwargs)
                return response
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç–∞."""
        pass


class LocationService:
    """–ü—Ä–æ—Å—Ç–æ–π —Å–µ—Ä–≤–∏—Å –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏."""
    
    def __init__(self):
        self.nominatim = Nominatim(user_agent="vkusvill-scraper/1.0")
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞–¥—Ä–µ—Å–∞
        self.test_addresses = {
            "–ú–æ—Å–∫–≤–∞, –ö—Ä–∞—Å–Ω–∞—è –ø–ª–æ—â–∞–¥—å, 1": (55.7539, 37.6208),
            "–ú–æ—Å–∫–≤–∞, –¢–≤–µ—Ä—Å–∫–∞—è —É–ª–∏—Ü–∞, 1": (55.7558, 37.6176),
            "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –ù–µ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç, 1": (59.9311, 30.3609),
        }
        
    async def geocode_address(self, address: str) -> Optional[tuple]:
        """–ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∞–¥—Ä–µ—Å –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞–¥—Ä–µ—Å–∞
        if address in self.test_addresses:
            return self.test_addresses[address]
            
        try:
            location = self.nominatim.geocode(address, timeout=10)
            if location:
                return (location.latitude, location.longitude)
        except (GeocoderTimedOut, GeocoderServiceError):
            pass
            
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ú–æ—Å–∫–≤—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return (55.7558, 37.6176)


class VkusvillFastParser:
    """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–µ—Ä –±–µ–∑ –∑–∞—Ö–æ–¥–∞ –≤ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤."""
    
    def __init__(self, antibot_client):
        self.antibot_client = antibot_client
        self.BASE_URL = "https://vkusvill.ru"
        self.heavy_data = {}  # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
        
    def load_heavy_data(self, heavy_file_path: str = None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞."""
        if not heavy_file_path:
            # –ü–æ–∏—Å–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∞–π–ª–∞ —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
            data_dir = Path("data")
            if data_dir.exists():
                heavy_files = list(data_dir.glob("moscow_improved_*.csv"))
                if heavy_files:
                    heavy_file_path = str(sorted(heavy_files)[-1])  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª
        
        if heavy_file_path and Path(heavy_file_path).exists():
            print(f"üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞: {heavy_file_path}")
            try:
                with open(heavy_file_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        self.heavy_data[row['id']] = row
                print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.heavy_data)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –±–∞–∑—ã")
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {e}")
        else:
            print("‚ö†Ô∏è –ë–∞–∑–∞ —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –∫–∞—Ç–∞–ª–æ–≥–æ–º")
    
    async def scrape_fast(self, city: str, coords: str, address: str = None, limit: int = 100) -> List[Dict]:
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ - —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø–æ –∞–¥—Ä–µ—Å—É, –ø–æ—Ç–æ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –±–∞–∑–æ–π."""
        print(f"‚ö° –ù–∞—á–∏–Ω–∞–µ–º –±—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–∞ {limit} —Ç–æ–≤–∞—Ä–æ–≤...")
        print(f"üìç –õ–æ–∫–∞—Ü–∏—è: {address or city}")
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–æ–∫–∞—Ü–∏–∏
        await self._set_location(city, coords)
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∞–¥—Ä–µ—Å—É
        print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∞–¥—Ä–µ—Å—É...")
        available_product_ids = await self._get_available_products(coords)
        print(f"üì¶ –ü–æ –∞–¥—Ä–µ—Å—É –¥–æ—Å—Ç—É–ø–Ω–æ: {len(available_product_ids)} —Ç–æ–≤–∞—Ä–æ–≤")
        
        products = []
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –±–∞–∑–∞ —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ - —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏
        if self.heavy_data and available_product_ids:
            print(f"üìö –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –±–∞–∑–æ–π —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞...")
            matched_count = 0
            
            for product_id in available_product_ids[:limit]:
                if product_id in self.heavy_data:
                    heavy_product = self.heavy_data[product_id]
                    product = {
                        'id': heavy_product.get('id', product_id),
                        'name': heavy_product.get('name', ''),
                        'price': heavy_product.get('price', ''),
                        'category': heavy_product.get('category', '–ì–æ—Ç–æ–≤–∞—è –µ–¥–∞'),
                        'url': heavy_product.get('url', ''),
                        'shop': 'vkusvill_address',
                        'photo': heavy_product.get('photo', ''),
                        'composition': heavy_product.get('composition', ''),
                        'tags': heavy_product.get('tags', ''),
                        'portion_g': heavy_product.get('portion_g', ''),
                        'kcal_100g': heavy_product.get('kcal_100g', ''),
                        'protein_100g': heavy_product.get('protein_100g', ''),
                        'fat_100g': heavy_product.get('fat_100g', ''),
                        'carb_100g': heavy_product.get('carb_100g', '')
                    }
                    products.append(product)
                    matched_count += 1
            
            print(f"‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ —Å –±–∞–∑–æ–π: {matched_count} —Ç–æ–≤–∞—Ä–æ–≤")
            print(f"‚ö° –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            return products
        
        # –ï—Å–ª–∏ –±–∞–∑—ã –Ω–µ—Ç - –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥
        print("‚ö†Ô∏è –ë–∞–∑–∞ —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –ø—É—Å—Ç–∞, –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥...")
        return await self._fallback_catalog_parsing(limit)
    
    async def _get_available_products(self, coords: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∞–¥—Ä–µ—Å—É."""
        available_ids = []
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≥–æ—Ç–æ–≤–æ–π –µ–¥—ã
        categories = [
            "/goods/gotovaya-eda/",
            "/goods/gotovaya-eda/salaty/",
            "/goods/gotovaya-eda/supy/",
            "/goods/gotovaya-eda/vtorye-blyuda/",
            "/goods/gotovaya-eda/zavtraki/",
        ]
        
        for category in categories:
            try:
                url = f"{self.BASE_URL}{category}"
                response = await self.antibot_client.request(method="GET", url=url)
                
                if response.status_code == 200 and HTMLParser:
                    parser = HTMLParser(response.text)
                    
                    # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
                    product_links = parser.css('a[href*="/goods/"][href$=".html"]')
                    
                    for link in product_links:
                        href = link.attributes.get('href')
                        if href:
                            product_id = self._extract_id_from_url(urljoin(self.BASE_URL, href))
                            if product_id and product_id not in available_ids:
                                available_ids.append(product_id)
                
                await asyncio.sleep(0.5)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
        
        return available_ids
    
    async def _fallback_catalog_parsing(self, limit: int) -> List[Dict]:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞ –µ—Å–ª–∏ –Ω–µ—Ç –±–∞–∑—ã."""
        categories = [
            "/goods/gotovaya-eda/",
            "/goods/gotovaya-eda/salaty/",
            "/goods/gotovaya-eda/supy/",
            "/goods/gotovaya-eda/vtorye-blyuda/",
            "/goods/gotovaya-eda/zavtraki/",
        ]
        
        products = []
        
        for category in categories:
            try:
                category_products = await self._parse_category_fast(category, limit - len(products))
                products.extend(category_products)
                print(f"   {category}: –Ω–∞–π–¥–µ–Ω–æ {len(category_products)} —Ç–æ–≤–∞—Ä–æ–≤")
                
                if len(products) >= limit:
                    break
                    
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
        
        print(f"‚ö° –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        return products[:limit]
    
    async def _set_location(self, city: str, coords: str):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–æ–∫–∞—Ü–∏–∏."""
        try:
            lat, lon = coords.split(',')
            location_url = f"{self.BASE_URL}/api/location?city={quote(city)}&lat={lat.strip()}&lon={lon.strip()}"
            await self.antibot_client.request(method="GET", url=location_url)
            print(f"üìç –õ–æ–∫–∞—Ü–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {city}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ª–æ–∫–∞—Ü–∏–∏: {e}")
    
    async def _parse_category_fast(self, category: str, max_products: int) -> List[Dict]:
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–µ–∑ –∑–∞—Ö–æ–¥–∞ –≤ –∫–∞—Ä—Ç–æ—á–∫–∏."""
        products = []
        
        try:
            url = f"{self.BASE_URL}{category}"
            print(f"   üîç –ü–∞—Ä—Å–∏–º: {url}")
            response = await self.antibot_client.request(method="GET", url=url)
            
            if response.status_code != 200:
                print(f"   ‚ùå HTTP {response.status_code}")
                return products
                
            if not HTMLParser:
                print(f"   ‚ùå HTMLParser –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                return products
                
            parser = HTMLParser(response.text)
            
            # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
            product_links = parser.css('a[href*="/goods/"][href$=".html"]')
            print(f"   üì¶ –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã: {len(product_links)}")
            
            for link in product_links:
                if len(products) >= max_products:
                    break
                    
                product = self._extract_product_from_link(link)
                if product:
                    # –î–æ–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
                    if product['id'] in self.heavy_data:
                        heavy_product = self.heavy_data[product['id']]
                        product.update({
                            'kcal_100g': heavy_product.get('kcal_100g', ''),
                            'protein_100g': heavy_product.get('protein_100g', ''),
                            'fat_100g': heavy_product.get('fat_100g', ''),
                            'carb_100g': heavy_product.get('carb_100g', ''),
                            'composition': heavy_product.get('composition', ''),
                            'photo': heavy_product.get('photo', ''),
                            'portion_g': heavy_product.get('portion_g', '')
                        })
                    
                    products.append(product)
                    print(f"   ‚úÖ {product['name'][:50]}...")
        
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
            import traceback
            traceback.print_exc()
        
        return products
    
    def _extract_product_from_link(self, link) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞ –∏–∑ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ç–∞–ª–æ–∂–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ."""
        try:
            url = urljoin(self.BASE_URL, link.attributes.get('href'))
            product_id = self._extract_id_from_url(url)
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Å—ã–ª–∫–∏ –∏–ª–∏ title
            name = link.text(strip=True) or link.attributes.get('title', '')
            
            # –ò—â–µ–º —Ü–µ–Ω—É –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
            parent = link.parent
            price = ""
            
            # –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
            for _ in range(3):  # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –¥–æ 3 —É—Ä–æ–≤–Ω–µ–π –≤–≤–µ—Ä—Ö
                if parent:
                    price_elements = parent.css('.price, [class*="price"], [class*="cost"]')
                    for price_elem in price_elements:
                        price_text = price_elem.text(strip=True)
                        match = re.search(r'(\d+(?:[.,]\d+)?)', price_text)
                        if match:
                            price = match.group(1).replace(',', '.')
                            break
                    if price:
                        break
                    parent = parent.parent
            
            if not name:
                return None
            
            return {
                'id': product_id,
                'name': name[:150],
                'price': price,
                'category': '–ì–æ—Ç–æ–≤–∞—è –µ–¥–∞',
                'url': url,
                'shop': 'vkusvill_fast',
                'photo': '',
                'composition': '',
                'tags': '',
                'portion_g': '',
                'kcal_100g': '',
                'protein_100g': '',
                'fat_100g': '',
                'carb_100g': ''
            }
            
        except Exception as e:
            return None
    
    def _extract_product_from_block(self, block) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞ –∏–∑ –±–ª–æ–∫–∞ –Ω–∞ –∫–∞—Ç–∞–ª–æ–∂–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ."""
        try:
            # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä
            link = block.css_first('a[href*="/goods/"][href$=".html"]')
            if not link:
                return None
            
            url = urljoin(self.BASE_URL, link.attributes.get('href'))
            product_id = self._extract_id_from_url(url)
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            name = ""
            name_selectors = ['h3', '.title', '.name', '[data-testid*="name"]']
            for selector in name_selectors:
                element = block.css_first(selector)
                if element and element.text(strip=True):
                    name = element.text(strip=True)
                    break
            
            if not name:
                # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å—Å—ã–ª–∫–∏
                name = link.text(strip=True)
            
            # –¶–µ–Ω–∞ —Ç–æ–≤–∞—Ä–∞
            price = ""
            price_selectors = ['.price', '.cost', '[data-testid*="price"]']
            for selector in price_selectors:
                element = block.css_first(selector)
                if element:
                    price_text = element.text(strip=True)
                    match = re.search(r'(\d+(?:[.,]\d+)?)', price_text)
                    if match:
                        price = match.group(1).replace(',', '.')
                        break
            
            # –§–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –±–ª–æ–∫–µ)
            photo = ""
            img = block.css_first('img')
            if img:
                src = img.attributes.get('src') or img.attributes.get('data-src')
                if src:
                    photo = urljoin(self.BASE_URL, src)
            
            if not name:
                return None
            
            return {
                'id': product_id,
                'name': name[:150],
                'price': price,
                'category': '–ì–æ—Ç–æ–≤–∞—è –µ–¥–∞',
                'url': url,
                'shop': 'vkusvill_fast',
                'photo': photo,
                'composition': '',
                'tags': '',
                'portion_g': '',
                'kcal_100g': '',
                'protein_100g': '',
                'fat_100g': '',
                'carb_100g': ''
            }
            
        except Exception as e:
            return None
    
    def _extract_id_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ URL."""
        match = re.search(r'/goods/([^/]+)\.html', url)
        return match.group(1) if match else str(hash(url))[-8:]


async def get_location_from_address(address: str) -> tuple:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ –∞–¥—Ä–µ—Å–∞."""
    try:
        location_service = LocationService()
        result = await location_service.geocode_address(address)
        if result:
            lat, lon = result
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ—Ä–æ–¥ –∏–∑ –∞–¥—Ä–µ—Å–∞
            city = address.split(',')[0].strip() if ',' in address else "–ú–æ—Å–∫–≤–∞"
            return city, f"{lat},{lon}"
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –∞–¥—Ä–µ—Å–∞: {address}")
            return None, None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return None, None


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞."""
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –µ—Å–ª–∏ –Ω–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if len(sys.argv) < 2:
        print("‚ö° –ë–´–°–¢–†–´–ô –ü–ê–†–°–ï–† –í–ö–£–°–í–ò–õ–õ–ê")
        print("=" * 40)
        print("üåç –í–≤–µ–¥–∏—Ç–µ –∞–¥—Ä–µ—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞:")
        print("   –ü—Ä–∏–º–µ—Ä—ã:")
        print("   ‚Ä¢ –ú–æ—Å–∫–≤–∞, –ö—Ä–∞—Å–Ω–∞—è –ø–ª–æ—â–∞–¥—å, 1")
        print("   ‚Ä¢ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –ù–µ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç, 10")  
        print("   ‚Ä¢ 55.7558,37.6176 (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)")
        print()
        
        try:
            address = input("–ê–¥—Ä–µ—Å: ").strip()
            if not address:
                print("‚ùå –ê–¥—Ä–µ—Å –Ω–µ —É–∫–∞–∑–∞–Ω")
                return
                
            limit_input = input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100): ").strip()
            limit = int(limit_input) if limit_input.isdigit() else 100
            
        except (KeyboardInterrupt, EOFError):
            print("\n‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return
    else:
        address = sys.argv[1]
        limit = int(sys.argv[2]) if len(sys.argv) > 2 else 100
    
    print()
    print("‚ö° –ë–´–°–¢–†–´–ô –ü–ê–†–°–ï–† –í–ö–£–°–í–ò–õ–õ–ê")
    print("=" * 40)
    print(f"üéØ –¶–µ–ª—å: {limit} —Ç–æ–≤–∞—Ä–æ–≤")
    print(f"üìç –ê–¥—Ä–µ—Å: {address}")
    print("‚ö° –†–µ–∂–∏–º: –ë—ã—Å—Ç—Ä—ã–π (—Ç–æ–ª—å–∫–æ –∫–∞—Ç–∞–ª–æ–≥)")
    print()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    if ',' in address and len(address.split(',')) == 2:
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∞–ø—Ä—è–º—É—é
        try:
            lat, lon = address.split(',')
            float(lat.strip())
            float(lon.strip())
            city = "–ú–æ—Å–∫–≤–∞"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            coords = address
        except ValueError:
            city, coords = await get_location_from_address(address)
            if not coords:
                return
    else:
        # –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–¥—Ä–µ—Å–∞
        city, coords = await get_location_from_address(address)
        if not coords:
            return
    
    logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
    
    antibot_client = AntiBotClient(concurrency=20, timeout=30)  # –ë—ã—Å—Ç—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    
    try:
        parser = VkusvillFastParser(antibot_client)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
        parser.load_heavy_data()
        
        start_time = time.time()
        products = await parser.scrape_fast(city, coords, address, limit)
        end_time = time.time()
        
        if not products:
            print("‚ùå –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–ñ–£
        with_bju = sum(1 for p in products if any(p.get(f) for f in ['kcal_100g', 'protein_100g', 'fat_100g', 'carb_100g']))
        from_heavy_db = sum(1 for p in products if p['id'] in parser.heavy_data)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        timestamp = int(time.time())
        csv_file = f"data/address_fast_{timestamp}.csv"
        jsonl_file = f"data/address_fast_{timestamp}.jsonl"
        
        Path("data").mkdir(exist_ok=True)
        
        if products:
            fieldnames = list(products[0].keys())
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(products)
        
        with open(jsonl_file, 'w', encoding='utf-8') as f:
            for product in products:
                f.write(json.dumps(product, ensure_ascii=False) + '\n')
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        duration = end_time - start_time
        print()
        print("‚ö° –ë–´–°–¢–†–´–ô –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù")
        print("=" * 40)
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
        print(f"   ‚Ä¢ –° –ë–ñ–£ –¥–∞–Ω–Ω—ã–º–∏: {with_bju} ({with_bju/len(products)*100:.1f}%)")
        print(f"   ‚Ä¢ –ò–∑ –±–∞–∑—ã —Ç—è–∂–µ–ª–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞: {from_heavy_db}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f} —Å–µ–∫—É–Ω–¥")
        print(f"üíæ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"   ‚Ä¢ CSV: {csv_file}")
        print(f"   ‚Ä¢ JSONL: {jsonl_file}")
                
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await antibot_client.close()


if __name__ == "__main__":
    asyncio.run(main())
