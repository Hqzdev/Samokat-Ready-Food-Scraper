#!/usr/bin/env python3
"""–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å–∫—Ä–µ–π–ø–µ—Ä–∞ - –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏."""

import asyncio
from app.models import ScrapingConfig
from app.scrapers import SamokratScraper
from app.utils.logger import setup_logger


async def quick_test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞."""
    setup_logger(level="INFO")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞
    config = ScrapingConfig(
        city="–ú–æ—Å–∫–≤–∞",
        address="–ö—Ä–∞—Å–Ω–∞—è –ø–ª–æ—â–∞–¥—å, 1",
        parallel_workers=2,
        max_retries=1,
        request_delay_min=1.0,
        request_delay_max=2.0,
        headless=True
    )
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ —Å–∫—Ä–µ–π–ø–µ—Ä–∞...")
    print(f"–ú–∞–≥–∞–∑–∏–Ω: –°–∞–º–æ–∫–∞—Ç")
    print(f"–ì–æ—Ä–æ–¥: {config.city}")
    print(f"–ê–¥—Ä–µ—Å: {config.address}")
    print("-" * 50)
    
    try:
        async with SamokratScraper(config) as scraper:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞
            original_scrape_category = scraper._scrape_category
            
            async def limited_scrape_category(category):
                items = await original_scrape_category(category)
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 —Ç–æ–≤–∞—Ä–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
                return items[:3]
            
            scraper._scrape_category = limited_scrape_category
            
            result = await scraper.scrape()
            
            print(f"‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"–ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {result.total_found}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result.successful}")
            print(f"–û—à–∏–±–æ–∫: {result.failed}")
            print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.duration_seconds:.1f} —Å–µ–∫")
            
            if result.items:
                print("\nüì¶ –ü—Ä–∏–º–µ—Ä—ã —Ç–æ–≤–∞—Ä–æ–≤:")
                for i, item in enumerate(result.items[:3], 1):
                    print(f"{i}. {item.name}")
                    print(f"   –¶–µ–Ω–∞: {item.price} —Ä—É–±")
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {item.category}")
                    if item.has_complete_nutrients():
                        print(f"   –ö–ë–ñ–£: {item.kcal_100g}–∫–∫–∞–ª, –ë{item.protein_100g}–≥, –ñ{item.fat_100g}–≥, –£{item.carb_100g}–≥")
                    print(f"   URL: {item.url}")
                    print()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –Ω—É—Ç—Ä–∏–µ–Ω—Ç–æ–≤
                completeness = scraper.get_nutrient_completeness_rate(result.items)
                print(f"ü•ó –ü–æ–ª–Ω–æ—Ç–∞ –Ω—É—Ç—Ä–∏–µ–Ω—Ç–æ–≤: {completeness:.1%}")
                
                if completeness >= 0.99:
                    print("‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: –û–¢–õ–ò–ß–ù–û")
                elif completeness >= 0.90:
                    print("‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: –•–û–†–û–®–û")
                else:
                    print("‚ùå –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False
    
    return True


if __name__ == "__main__":
    success = asyncio.run(quick_test())
    if success:
        print("\nüéâ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ! –°–∫—Ä–µ–π–ø–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")
    else:
        print("\nüí• –¢–µ—Å—Ç –Ω–µ –ø—Ä–æ—à–µ–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.")
        exit(1)
