#!/usr/bin/env python3
"""
üîß –°–ö–†–ò–ü–¢ –î–û–ë–û–†–ê –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –î–ê–ù–ù–´–•
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç CSV —Ñ–∞–π–ª, –Ω–∞—Ö–æ–¥–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å –Ω–µ–ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –¥–æ–±–∏—Ä–∞–µ—Ç –∏—Ö.
"""

import asyncio
import csv
import json
import pandas as pd
import re
import sys
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urljoin

try:
    from selectolax.parser import HTMLParser
except ImportError:
    HTMLParser = None

import httpx


class DataRefiller:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–æ–±–æ—Ä–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(self):
        self.BASE_URL = "https://vkusvill.ru"
        
    async def analyze_and_refill(self, csv_file: str):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç CSV –∏ –¥–æ–±–∏—Ä–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ."""
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {csv_file}")
        
        # –ß–∏—Ç–∞–µ–º CSV
        df = pd.read_csv(csv_file)
        print(f"üìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–∞–π–ª–µ: {len(df)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        incomplete_products = []
        
        for index, row in df.iterrows():
            issues = []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ë–ñ–£
            bju_fields = ['kcal_100g', 'protein_100g', 'fat_100g', 'carb_100g']
            filled_bju = sum(1 for field in bju_fields if pd.notna(row[field]) and str(row[field]).strip())
            
            if filled_bju < 4:
                issues.append(f"–ë–ñ–£:{filled_bju}/4")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–Ω—É
            if pd.isna(row['price']) or not str(row['price']).strip():
                issues.append("–ù–ï–¢_–¶–ï–ù–´")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–∞–≤
            if pd.isna(row['composition']) or not str(row['composition']).strip():
                issues.append("–ù–ï–¢_–°–û–°–¢–ê–í–ê")
            
            if issues:
                incomplete_products.append({
                    'index': index,
                    'id': row['id'],
                    'name': row['name'][:50],
                    'url': row['url'],
                    'issues': issues
                })
        
        print(f"‚ùå –¢–æ–≤–∞—Ä–æ–≤ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏: {len(incomplete_products)}")
        print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(df) - len(incomplete_products)} ({(len(df) - len(incomplete_products))/len(df)*100:.1f}%)")
        
        if not incomplete_products:
            print("üéâ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –ø–æ–ª–Ω—ã–µ!")
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–±–ª–µ–º
        issue_stats = {}
        for product in incomplete_products:
            for issue in product['issues']:
                issue_stats[issue] = issue_stats.get(issue, 0) + 1
        
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú:")
        for issue, count in issue_stats.items():
            print(f"   ‚Ä¢ {issue}: {count} —Ç–æ–≤–∞—Ä–æ–≤")
        
        # –î–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print(f"\nüîß –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(incomplete_products)} —Ç–æ–≤–∞—Ä–æ–≤...")
        
        async with httpx.AsyncClient(timeout=30) as client:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            client.headers.update(headers)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–∞—Ç—á–∞–º–∏
            batch_size = 5
            updated_count = 0
            
            for i in range(0, len(incomplete_products), batch_size):
                batch = incomplete_products[i:i + batch_size]
                print(f"üîß –î–æ–±–∏—Ä–∞–µ–º {i+1}-{min(i+batch_size, len(incomplete_products))}/{len(incomplete_products)}")
                
                for product in batch:
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–Ω–æ–≤–æ –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ
                        updated_data = await self._refill_product_data(client, product['url'], product['issues'])
                        
                        if updated_data:
                            # –û–±–Ω–æ–≤–ª—è–µ–º DataFrame
                            for field, value in updated_data.items():
                                if value:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ
                                    df.at[product['index'], field] = value
                                    updated_count += 1
                            
                            print(f"      ‚úÖ {product['name']}... –æ–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª–µ–π: {len([v for v in updated_data.values() if v])}")
                        else:
                            print(f"      ‚ùå {product['name']}... –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å")
                            
                    except Exception as e:
                        print(f"      ‚ùå {product['name']}... –æ—à–∏–±–∫–∞: {e}")
                        continue
                
                await asyncio.sleep(1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        output_file = csv_file.replace('.csv', '_refilled.csv')
        df.to_csv(output_file, index=False)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüèÅ –î–û–ë–û–† –ó–ê–í–ï–†–®–ï–ù")
        print(f"üìä –û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª–µ–π: {updated_count}")
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        final_quality = self._calculate_quality(df)
        print(f"‚≠ê –ò—Ç–æ–≥–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ: {final_quality:.1f}%")
        
    async def _refill_product_data(self, client, url: str, issues: List[str]) -> Dict[str, str]:
        """–î–æ–±–∏—Ä–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–≤–∞—Ä–∞."""
        try:
            response = await client.get(url)
            if response.status_code != 200:
                return {}
                
            parser = HTMLParser(response.text)
            page_text = response.text
            
            updated_data = {}
            
            # –î–æ–±–∏—Ä–∞–µ–º —Ü–µ–Ω—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if "–ù–ï–¢_–¶–ï–ù–´" in issues:
                price = self._extract_price_enhanced(parser, page_text)
                if price:
                    updated_data['price'] = price
            
            # –î–æ–±–∏—Ä–∞–µ–º —Å–æ—Å—Ç–∞–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if "–ù–ï–¢_–°–û–°–¢–ê–í–ê" in issues:
                composition = self._extract_composition_enhanced(parser, page_text)
                if composition:
                    updated_data['composition'] = composition
            
            # –î–æ–±–∏—Ä–∞–µ–º –ë–ñ–£ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if any("–ë–ñ–£:" in issue for issue in issues):
                nutrition = self._extract_bju_enhanced(parser, page_text)
                for field, value in nutrition.items():
                    if value:
                        updated_data[field] = value
            
            return updated_data
            
        except Exception:
            return {}
    
    def _extract_price_enhanced(self, parser, page_text: str) -> str:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã."""
        # –ú–µ—Ç–æ–¥ 1: –í—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Ü–µ–Ω—ã
        price_selectors = [
            '.price', '.product-price', '.cost', '.goods-price', 
            '[class*="price"]', '[data-price]', '.current-price',
            '.js-product-price', '[class*="cost"]'
        ]
        
        for selector in price_selectors:
            elements = parser.css(selector)
            for element in elements:
                price_text = element.text(strip=True)
                numbers = re.findall(r'(\d+(?:[.,]\d+)?)', price_text)
                for num in numbers:
                    try:
                        price_val = float(num.replace(',', '.'))
                        if 10 <= price_val <= 10000:
                            return num.replace(',', '.')
                    except ValueError:
                        continue
        
        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        price_attrs = parser.css('[data-price], [value*="price"], [content*="price"]')
        for element in price_attrs:
            for attr in ['data-price', 'value', 'content']:
                attr_value = element.attributes.get(attr, '')
                if attr_value:
                    numbers = re.findall(r'(\d+(?:[.,]\d+)?)', attr_value)
                    for num in numbers:
                        try:
                            price_val = float(num.replace(',', '.'))
                            if 10 <= price_val <= 10000:
                                return num.replace(',', '.')
                        except ValueError:
                            continue
        
        # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        text_patterns = [
            r'(\d+(?:[.,]\d+)?)\s*—Ä—É–±',
            r'(\d+(?:[.,]\d+)?)\s*‚ÇΩ',
            r'—Ü–µ–Ω–∞[:\s]*(\d+(?:[.,]\d+)?)',
            r'—Å—Ç–æ–∏–º–æ—Å—Ç—å[:\s]*(\d+(?:[.,]\d+)?)',
            r'price[:\s]*(\d+(?:[.,]\d+)?)'
        ]
        for pattern in text_patterns:
            matches = re.finditer(pattern, page_text, re.I)
            for match in matches:
                try:
                    price_val = float(match.group(1).replace(',', '.'))
                    if 10 <= price_val <= 10000:
                        return match.group(1).replace(',', '.')
                except ValueError:
                    continue
        
        return ""
    
    def _extract_composition_enhanced(self, parser, page_text: str) -> str:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∞."""
        # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É "–°–æ—Å—Ç–∞–≤" —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
        elements = parser.css('div, p, span, td, li, section, article, main')
        for element in elements:
            text = element.text().strip()
            text_lower = text.lower()
            
            if '—Å–æ—Å—Ç–∞–≤' in text_lower and len(text) > 15:
                # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                if not any(word in text_lower for word in ['–º–µ–Ω—é', '–∫–∞—Ç–∞–ª–æ–≥', '–∫–æ—Ä–∑–∏–Ω–∞', '–Ω–∞–≤–∏–≥–∞—Ü–∏—è', '–≤–∫—É—Å–≤–∏–ª–ª', '–¥–æ—Å—Ç–∞–≤–∫–∞']):
                    if text_lower.startswith('—Å–æ—Å—Ç–∞–≤'):
                        return text[:800]
                    elif len(text) < 800 and '—Å–æ—Å—Ç–∞–≤' in text_lower:
                        return text[:500]
        
        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –≤ –º–µ—Ç–∞-—Ç–µ–≥–∞—Ö
        meta_tags = parser.css('meta[name*="description"], meta[property*="description"]')
        for meta in meta_tags:
            content = meta.attributes.get('content', '')
            if '—Å–æ—Å—Ç–∞–≤' in content.lower() and len(content) > 20:
                return content[:500]
        
        # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –≤ JSON-LD —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        try:
            scripts = parser.css('script[type="application/ld+json"]')
            for script in scripts:
                try:
                    data = json.loads(script.text())
                    
                    def extract_from_json(obj):
                        if isinstance(obj, dict):
                            for key, value in obj.items():
                                if isinstance(value, str) and '—Å–æ—Å—Ç–∞–≤' in value.lower() and len(value) > 20:
                                    return value[:500]
                                elif isinstance(value, (dict, list)):
                                    result = extract_from_json(value)
                                    if result:
                                        return result
                        elif isinstance(obj, list):
                            for item in obj:
                                result = extract_from_json(item)
                                if result:
                                    return result
                        return None
                    
                    composition = extract_from_json(data)
                    if composition:
                        return composition
                        
                except json.JSONDecodeError:
                    continue
        except:
            pass
        
        return ""
    
    def _extract_bju_enhanced(self, parser, page_text: str) -> Dict[str, str]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ë–ñ–£."""
        nutrition = {'kcal_100g': '', 'protein_100g': '', 'fat_100g': '', 'carb_100g': ''}
        
        # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
        elements = parser.css('div, span, p, td, th, li, section')
        for element in elements:
            text = element.text().lower()
            
            if any(word in text for word in ['–∫–∫–∞–ª', '–±–µ–ª–∫–∏', '–∂–∏—Ä—ã', '—É–≥–ª–µ–≤–æ–¥—ã', '–∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å', '—ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è']):
                # –ö–∞–ª–æ—Ä–∏–∏ - –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                if ('–∫–∫–∞–ª' in text or '–∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å' in text or '—ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è' in text) and not nutrition['kcal_100g']:
                    kcal_patterns = [
                        r'(\d+(?:[.,]\d+)?)\s*–∫–∫–∞–ª',
                        r'–∫–∫–∞–ª[:\s]*(\d+(?:[.,]\d+)?)',
                        r'–∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å[:\s]*(\d+(?:[.,]\d+)?)',
                        r'—ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è\s+—Ü–µ–Ω–Ω–æ—Å—Ç—å[:\s]*(\d+(?:[.,]\d+)?)',
                        r'(\d+(?:[.,]\d+)?)\s+–∫–∫–∞–ª',
                        r'—ç–Ω–µ—Ä–≥–∏—è[:\s]*(\d+(?:[.,]\d+)?)'
                    ]\n                    for pattern in kcal_patterns:
                        match = re.search(pattern, text)
                        if match:
                            try:
                                val = float(match.group(1).replace(',', '.'))
                                if 10 <= val <= 900:
                                    nutrition['kcal_100g'] = match.group(1).replace(',', '.')
                                    break
                            except ValueError:
                                continue
                
                # –ë–µ–ª–∫–∏ - –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                if '–±–µ–ª–∫' in text and not nutrition['protein_100g']:
                    protein_patterns = [
                        r'(\d+(?:[.,]\d+)?)\s+–±–µ–ª–∫–∏,\s*–≥',
                        r'–±–µ–ª–∫[–∏–∞][:\s]*(\d+(?:[.,]\d+)?)',
                        r'–±–µ–ª–æ–∫[:\s]*(\d+(?:[.,]\d+)?)',
                        r'–ø—Ä–æ—Ç–µ–∏–Ω[:\s]*(\d+(?:[.,]\d+)?)',
                        r'(\d+(?:[.,]\d+)?)\s*–≥\s*–±–µ–ª–∫'
                    ]
                    for pattern in protein_patterns:
                        match = re.search(pattern, text)
                        if match:
                            try:
                                val = float(match.group(1).replace(',', '.'))
                                if 0 <= val <= 100:
                                    nutrition['protein_100g'] = match.group(1).replace(',', '.')
                                    break
                            except ValueError:
                                continue
                
                # –ñ–∏—Ä—ã - –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                if '–∂–∏—Ä' in text and not nutrition['fat_100g']:
                    fat_patterns = [
                        r'(\d+(?:[.,]\d+)?)\s+–∂–∏—Ä—ã,\s*–≥',
                        r'–∂–∏—Ä[—ã–∞][:\s]*(\d+(?:[.,]\d+)?)',
                        r'–∂–∏—Ä[:\s]*(\d+(?:[.,]\d+)?)',
                        r'(\d+(?:[.,]\d+)?)\s*–≥\s*–∂–∏—Ä'
                    ]
                    for pattern in fat_patterns:
                        match = re.search(pattern, text)
                        if match:
                            try:
                                val = float(match.group(1).replace(',', '.'))
                                if 0 <= val <= 100:
                                    nutrition['fat_100g'] = match.group(1).replace(',', '.')
                                    break
                            except ValueError:
                                continue
                
                # –£–≥–ª–µ–≤–æ–¥—ã - –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                if '—É–≥–ª–µ–≤–æ–¥' in text and not nutrition['carb_100g']:
                    carb_patterns = [
                        r'(\d+(?:[.,]\d+)?)\s+—É–≥–ª–µ–≤–æ–¥—ã,\s*–≥',
                        r'—É–≥–ª–µ–≤–æ–¥[—ã–∞][:\s]*(\d+(?:[.,]\d+)?)',
                        r'—É–≥–ª–µ–≤–æ–¥[:\s]*(\d+(?:[.,]\d+)?)',
                        r'(\d+(?:[.,]\d+)?)\s*–≥\s*—É–≥–ª–µ–≤–æ–¥'
                    ]
                    for pattern in carb_patterns:
                        match = re.search(pattern, text)
                        if match:
                            try:
                                val = float(match.group(1).replace(',', '.'))
                                if 0 <= val <= 100:
                                    nutrition['carb_100g'] = match.group(1).replace(',', '.')
                                    break
                            except ValueError:
                                continue
        
        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
        try:
            tables = parser.css('table')
            for table in tables:
                rows = table.css('tr')
                for row in rows:
                    cells = row.css('td, th')
                    if len(cells) >= 2:
                        header = cells[0].text().lower()
                        value_text = cells[1].text()
                        
                        num_match = re.search(r'(\d+(?:[.,]\d+)?)', value_text)
                        if num_match:
                            value = num_match.group(1).replace(',', '.')
                            
                            if ('–∫–∫–∞–ª' in header or '–∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å' in header) and not nutrition['kcal_100g']:
                                nutrition['kcal_100g'] = value
                            elif '–±–µ–ª–∫' in header and not nutrition['protein_100g']:
                                nutrition['protein_100g'] = value
                            elif '–∂–∏—Ä' in header and not nutrition['fat_100g']:
                                nutrition['fat_100g'] = value
                            elif '—É–≥–ª–µ–≤–æ–¥' in header and not nutrition['carb_100g']:
                                nutrition['carb_100g'] = value
        except:
            pass
        
        return nutrition
    
    def _calculate_quality(self, df) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö."""
        total_score = 0
        max_score = 0
        
        for _, row in df.iterrows():
            # –ë–ñ–£ (4 –±–∞–ª–ª–∞ –º–∞–∫—Å–∏–º—É–º)
            bju_fields = ['kcal_100g', 'protein_100g', 'fat_100g', 'carb_100g']
            bju_score = sum(1 for field in bju_fields if pd.notna(row[field]) and str(row[field]).strip())
            
            # –°–æ—Å—Ç–∞–≤ (1 –±–∞–ª–ª)
            composition_score = 1 if pd.notna(row['composition']) and str(row['composition']).strip() else 0
            
            # –¶–µ–Ω–∞ (1 –±–∞–ª–ª)
            price_score = 1 if pd.notna(row['price']) and str(row['price']).strip() else 0
            
            total_score += bju_score + composition_score + price_score
            max_score += 6  # 4 + 1 + 1
        
        return (total_score / max_score) * 100 if max_score > 0 else 0


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö."""
    if len(sys.argv) < 2:
        print("‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python refill_data.py <–ø—É—Ç—å_–∫_csv_—Ñ–∞–π–ª—É>")
        return
    
    csv_file = sys.argv[1]
    
    if not Path(csv_file).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_file}")
        return
    
    print("üîß –°–ö–†–ò–ü–¢ –î–û–ë–û–†–ê –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –î–ê–ù–ù–´–•")
    print("=" * 50)
    
    refiller = DataRefiller()
    await refiller.analyze_and_refill(csv_file)


if __name__ == "__main__":
    asyncio.run(main())
